TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor 
to host memory first.

The above exception was the direct cause of the following exception:

╭────────────────────────────── Traceback (most recent call last) ───────────────────────────────╮
│ /content/booster_soccer_showdown/training_scripts/main_simple_dreamerv3.py:386 in <module>     │
│                                                                                                │
│   383 print("=== Starting Evaluation ===")                                                     │
│   384                                                                                          │
│   385 ## Benchmark the model locally                                                           │
│ ❱ 386 sai.benchmark(model, action_function, Preprocessor)                                      │
│   387                                                                                          │
│   388 ## Submit to leaderboard                                                                 │
│   389 print("=== Submitting to Leaderboard ===")                                               │
│                                                                                                │
│ ╭────────────────────────────────────────── locals ──────────────────────────────────────────╮ │
│ │    env = <CustomEvaluationWrapper<TimeLimit<OrderEnforcing<PassiveEnvChecker<GoaliePenalt… │ │
│ │      F = <module 'torch.nn.functional' from                                                │ │
│ │          '/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py'>                 │ │
│ │  model = SimpleDreamerV3(                                                                  │ │
│ │            (rssm): RSSMCore(                                                               │ │
│ │          │   (obs_encoder): Sequential(                                                    │ │
│ │          │     (0): Linear(in_features=89, out_features=256, bias=True)                    │ │
│ │          │     (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)                  │ │
│ │          │     (2): ReLU()                                                                 │ │
│ │          │     (3): Linear(in_features=256, out_features=256, bias=True)                   │ │
│ │          │     (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)                  │ │
│ │          │     (5): ReLU()                                                                 │ │
│ │          │   )                                                                             │ │
│ │          │   (rnn): GRUCell(268, 256)                                                      │ │
│ │          │   (prior_net): Linear(in_features=256, out_features=512, bias=True)             │ │
│ │          │   (posterior_net): Linear(in_features=512, out_features=512, bias=True)         │ │
│ │          │   (obs_decoder): Sequential(                                                    │ │
│ │          │     (0): Linear(in_features=768, out_features=256, bias=True)                   │ │
│ │          │     (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)                  │ │
│ │          │     (2): ReLU()                                                                 │ │
│ │          │     (3): Linear(in_features=256, out_features=256, bias=True)                   │ │
│ │          │     (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)                  │ │
│ │          │     (5): ReLU()                                                                 │ │
│ │          │     (6): Linear(in_features=256, out_features=89, bias=True)                    │ │
│ │          │   )                                                                             │ │
│ │          │   (reward_predictor): Sequential(                                               │ │
│ │          │     (0): Linear(in_features=768, out_features=128, bias=True)                   │ │
│ │          │     (1): ReLU()                                                                 │ │
│ │          │     (2): Linear(in_features=128, out_features=1, bias=True)                     │ │
│ │          │   )                                                                             │ │
│ │            )                                                                               │ │
│ │            (actor): Actor(                                                                 │ │
│ │          │   (net): Sequential(                                                            │ │
│ │          │     (0): Linear(in_features=768, out_features=256, bias=True)                   │ │
│ │          │     (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)                  │ │
│ │          │     (2): ReLU()                                                                 │ │
│ │          │     (3): Linear(in_features=256, out_features=256, bias=True)                   │ │
│ │          │     (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)                  │ │
│ │          │     (5): ReLU()                                                                 │ │
│ │          │     (6): Linear(in_features=256, out_features=256, bias=True)                   │ │
│ │          │     (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)                  │ │
│ │          │     (8): ReLU()                                                                 │ │
│ │          │     (9): Linear(in_features=256, out_features=12, bias=True)                    │ │
│ │          │   )                                                                             │ │
│ │            )                                                                               │ │
│ │            (critic): Critic(                                                               │ │
│ │          │   (net): Sequential(                                                            │ │
│ │          │     (0): Linear(in_features=768, out_features=256, bias=True)                   │ │
│ │          │     (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)                  │ │
│ │          │     (2): ReLU()                                                                 │ │
│ │          │     (3): Linear(in_features=256, out_features=256, bias=True)                   │ │
│ │          │     (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)                  │ │
│ │          │     (5): ReLU()                                                                 │ │
│ │          │     (6): Linear(in_features=256, out_features=256, bias=True)                   │ │
│ │          │     (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)                  │ │
│ │          │     (8): ReLU()                                                                 │ │
│ │          │     (9): Linear(in_features=256, out_features=1, bias=True)                     │ │
│ │          │   )                                                                             │ │
│ │            )                                                                               │ │
│ │            (target_critic): Critic(                                                        │ │
│ │          │   (net): Sequential(                                                            │ │
│ │          │     (0): Linear(in_features=768, out_features=256, bias=True)                   │ │
│ │          │     (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)                  │ │
│ │          │     (2): ReLU()                                                                 │ │
│ │          │     (3): Linear(in_features=256, out_features=256, bias=True)                   │ │
│ │          │     (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)                  │ │
│ │          │     (5): ReLU()                                                                 │ │
│ │          │     (6): Linear(in_features=256, out_features=256, bias=True)                   │ │
│ │          │     (7): LayerNorm((256,), eps=1e-05, elementwise_affine=True)                  │ │
│ │          │     (8): ReLU()                                                                 │ │
│ │          │     (9): Linear(in_features=256, out_features=1, bias=True)                     │ │
│ │          │   )                                                                             │ │
│ │            )                                                                               │ │
│ │          )                                                                                 │ │
│ │     np = <module 'numpy' from '/usr/local/lib/python3.12/dist-packages/numpy/__init__.py'> │ │
│ │     os = <module 'os' (frozen)>                                                            │ │
│ │ random = <module 'random' from '/usr/lib/python3.12/random.py'>                            │ │
│ │    sai = <sai_rl.sai_client.SAIClient object at 0x7aa3d6bf8ef0>                            │ │
│ │  torch = <module 'torch' from '/usr/local/lib/python3.12/dist-packages/torch/__init__.py'> │ │
│ ╰────────────────────────────────────────────────────────────────────────────────────────────╯ │
│                                                                                                │
│ /usr/local/lib/python3.12/dist-packages/sai_rl/sai_client.py:818 in benchmark                  │
│                                                                                                │
│    815 │   │   │   results["duration"] = time.time() - start_time                              │
│    816 │   │   │                                                                               │
│    817 │   │   │   if error and throw_errors:                                                  │
│ ❱  818 │   │   │   │   raise error                                                             │
│    819 │   │   │                                                                               │
│    820 │   │   │   if self._log_capture:                                                       │
│    821 │   │   │   │   results["logs"] = self._get_logs()  