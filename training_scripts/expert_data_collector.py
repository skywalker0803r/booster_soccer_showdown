"""
å°ˆå®¶è»Œè·¡æ”¶é›†å™¨ - æ•´åˆæ‰‹å‹•é™æ§å’Œæ•¸æ“šè¨˜éŒ„
åŸºæ–¼ booster_control/teleoperate.py ä¿®æ”¹ï¼Œæ·»åŠ è»Œè·¡è¨˜éŒ„åŠŸèƒ½
"""

import argparse
import numpy as np
import pickle
import os
from datetime import datetime
from pathlib import Path
import sai_mujoco  # noqa: F401
import gymnasium as gym
import sys

# æ·»åŠ  booster_control åˆ°è·¯å¾‘
import os
current_dir = os.path.dirname(os.path.abspath(__file__))
booster_control_path = os.path.join(os.path.dirname(current_dir), 'booster_control')
sys.path.insert(0, booster_control_path)

try:
    from se3_keyboard import Se3Keyboard, Se3Keyboard_Pynput
    from t1_utils import LowerT1JoyStick
    print(f"âœ… æˆåŠŸå°å…¥ booster_control æ¨¡çµ„")
except ImportError as e:
    print(f"âŒ å°å…¥æ¨¡çµ„å¤±æ•—: {e}")
    print(f"ğŸ” å˜—è©¦çš„è·¯å¾‘: {booster_control_path}")
    print(f"ğŸ“ ç•¶å‰ç›®éŒ„å…§å®¹: {os.listdir('.')}")
    if os.path.exists('booster_control'):
        print(f"ğŸ“ booster_control å…§å®¹: {os.listdir('booster_control')}")
    raise


class ExpertTrajectoryCollector:
    """å°ˆå®¶è»Œè·¡æ”¶é›†å™¨"""
    
    def __init__(self, save_dir="expert_data"):
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)
        
        # ç•¶å‰episodeçš„æ•¸æ“š
        self.current_episode = {
            'observations': [],
            'actions': [],
            'rewards': [],
            'info_history': [],
            'episode_reward': 0
        }
        
        # æ‰€æœ‰æ”¶é›†çš„è»Œè·¡
        self.all_trajectories = []
        self.episode_count = 0
        
        print(f"ğŸ¯ å°ˆå®¶è»Œè·¡æ”¶é›†å™¨åˆå§‹åŒ–")
        print(f"ğŸ“ æ•¸æ“šä¿å­˜ç›®éŒ„: {save_dir}")
    
    def start_episode(self, observation, info):
        """é–‹å§‹æ–°çš„episode"""
        self.current_episode = {
            'observations': [observation.copy()],
            'actions': [],
            'rewards': [],
            'info_history': [info.copy()],
            'episode_reward': 0,
            'start_time': datetime.now()
        }
        self.episode_count += 1
        print(f"\nğŸ® Episode {self.episode_count} é–‹å§‹è¨˜éŒ„...")
    
    def record_step(self, observation, action, reward, info):
        """è¨˜éŒ„å–®æ­¥æ•¸æ“š"""
        self.current_episode['observations'].append(observation.copy())
        self.current_episode['actions'].append(action.copy())
        self.current_episode['rewards'].append(reward)
        self.current_episode['info_history'].append(info.copy())
        self.current_episode['episode_reward'] += reward
    
    def end_episode(self, success=False):
        """çµæŸepisodeä¸¦æ±ºå®šæ˜¯å¦ä¿å­˜"""
        duration = datetime.now() - self.current_episode['start_time']
        reward = self.current_episode['episode_reward']
        steps = len(self.current_episode['actions'])
        
        print(f"ğŸ“Š Episode {self.episode_count} å®Œæˆ:")
        print(f"   çå‹µ: {reward:.3f}")
        print(f"   æ­¥æ•¸: {steps}")
        print(f"   æ™‚é•·: {duration.total_seconds():.1f}ç§’")
        print(f"   æˆåŠŸ: {'âœ…' if success else 'âŒ'}")
        
        # è©¢å•æ˜¯å¦ä¿å­˜é€™å€‹episode
        if success or reward > -10:  # è‡ªå‹•ä¿å­˜æˆåŠŸæˆ–é‚„ä¸éŒ¯çš„episode
            save_choice = input(f"ğŸ’¾ ä¿å­˜é€™å€‹episodeå—ï¼Ÿ[Y/n]: ").strip().lower()
            if save_choice in ['', 'y', 'yes']:
                self._save_episode(quality="good")
        elif reward > -50:  # ä¸­ç­‰è¡¨ç¾
            save_choice = input(f"ğŸ“ é€™å€‹episodeè¡¨ç¾ä¸€èˆ¬ï¼Œä¿å­˜å—ï¼Ÿ[y/N]: ").strip().lower()
            if save_choice in ['y', 'yes']:
                self._save_episode(quality="medium")
        else:  # è¡¨ç¾å¾ˆå·®
            save_choice = input(f"ğŸ—‘ï¸  é€™å€‹episodeè¡¨ç¾è¼ƒå·®ï¼Œä»è¦ä¿å­˜å—ï¼Ÿ[y/N]: ").strip().lower()
            if save_choice in ['y', 'yes']:
                self._save_episode(quality="poor")
        
        print(f"ğŸ“ˆ ç›®å‰å·²ä¿å­˜ {len(self.all_trajectories)} æ¢è»Œè·¡")
    
    def _save_episode(self, quality="good"):
        """ä¿å­˜episode"""
        # æ·»åŠ è³ªé‡æ¨™ç±¤
        self.current_episode['quality'] = quality
        self.current_episode['collection_time'] = datetime.now().isoformat()
        
        # è½‰æ›ç‚ºnumpy arrays
        episode_data = {
            'observations': np.array(self.current_episode['observations'][:-1]),  # ç§»é™¤æœ€å¾Œä¸€å€‹obs
            'actions': np.array(self.current_episode['actions']),
            'rewards': np.array(self.current_episode['rewards']),
            'episode_reward': self.current_episode['episode_reward'],
            'quality': quality,
            'collection_time': self.current_episode['collection_time'],
            'episode_id': self.episode_count
        }
        
        self.all_trajectories.append(episode_data)
        print(f"âœ… Episode {self.episode_count} å·²ä¿å­˜ ({quality} quality)")
        
        # è‡ªå‹•ä¿å­˜åˆ°æ–‡ä»¶
        self.save_to_file()
    
    def save_to_file(self, filename=None):
        """ä¿å­˜æ‰€æœ‰è»Œè·¡åˆ°æ–‡ä»¶"""
        if not self.all_trajectories:
            return
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"expert_trajectories_{timestamp}.pkl"
        
        filepath = os.path.join(self.save_dir, filename)
        
        with open(filepath, 'wb') as f:
            pickle.dump(self.all_trajectories, f)
        
        print(f"ğŸ’¾ å·²ä¿å­˜ {len(self.all_trajectories)} æ¢è»Œè·¡åˆ° {filepath}")
    
    def print_statistics(self):
        """æ‰“å°æ”¶é›†çµ±è¨ˆ"""
        if not self.all_trajectories:
            print("ğŸ“Š å°šæœªæ”¶é›†ä»»ä½•è»Œè·¡")
            return
        
        rewards = [traj['episode_reward'] for traj in self.all_trajectories]
        lengths = [len(traj['actions']) for traj in self.all_trajectories]
        qualities = [traj['quality'] for traj in self.all_trajectories]
        
        print(f"\nğŸ“Š æ”¶é›†çµ±è¨ˆ:")
        print(f"   ç¸½è»Œè·¡æ•¸: {len(self.all_trajectories)}")
        print(f"   å¹³å‡çå‹µ: {np.mean(rewards):.3f}")
        print(f"   æœ€ä½³çå‹µ: {max(rewards):.3f}")
        print(f"   æœ€å·®çå‹µ: {min(rewards):.3f}")
        print(f"   å¹³å‡é•·åº¦: {np.mean(lengths):.1f} æ­¥")
        print(f"   è³ªé‡åˆ†å¸ƒ: Good={qualities.count('good')}, Medium={qualities.count('medium')}, Poor={qualities.count('poor')}")


def expert_teleoperate(
    env_name: str = "LowerT1GoaliePenaltyKick-v0",
    pos_sensitivity: float = 0.1,
    rot_sensitivity: float = 1.5,
    renderer="mjviewer"
):
    """å°ˆå®¶é™æ§withè»Œè·¡è¨˜éŒ„"""
    
    print("ğŸ¯ å°ˆå®¶è»Œè·¡æ”¶é›†æ¨¡å¼")
    print("="*60)
    print("ğŸ® ä½ å°‡æ‰‹å‹•æ“ä½œæ©Ÿå™¨äººè¸¢è¶³çƒ")
    print("ğŸ“ ç³»çµ±æœƒè‡ªå‹•è¨˜éŒ„ä½ çš„æ“ä½œä½œç‚ºå°ˆå®¶æ¼”ç¤º")
    print("ğŸ’¡ å»ºè­°:")
    print("   - å˜—è©¦è®“æ©Ÿå™¨äººä¿æŒç©©å®š")
    print("   - æ…¢æ…¢æ¥è¿‘çƒ")
    print("   - å¦‚æœæˆåŠŸè«‹ä¿å­˜è»Œè·¡")
    print("   - ESCéµé€€å‡º")
    print("="*60)
    
    # å‰µå»ºç’°å¢ƒ
    env = gym.make(env_name, render_mode="human", renderer=renderer)
    lower_t1_robot = LowerT1JoyStick(env.unwrapped)
    
    # å‰µå»ºè»Œè·¡æ”¶é›†å™¨
    collector = ExpertTrajectoryCollector()
    
    # åˆå§‹åŒ–éµç›¤æ§åˆ¶å™¨
    if renderer == "mjviewer":
        keyboard_controller = Se3Keyboard_Pynput(
            renderer=env.unwrapped.mujoco_renderer,
            pos_sensitivity=pos_sensitivity,
            rot_sensitivity=rot_sensitivity,
        )
    else:
        keyboard_controller = Se3Keyboard(
            renderer=env.unwrapped.mujoco_renderer,
            pos_sensitivity=pos_sensitivity,
            rot_sensitivity=rot_sensitivity,
        )
    
    # è¨­ç½®é‡ç½®å›èª¿
    keyboard_controller.set_reset_env_callback(env.reset)
    
    # æ‰“å°æ§åˆ¶èªªæ˜
    print("\nğŸ® éµç›¤æ§åˆ¶:")
    print(keyboard_controller)
    print("\nğŸ“ æ•¸æ“šæ”¶é›†:")
    print("   - æ¯å€‹episodeçµæŸå¾Œæœƒè©¢å•æ˜¯å¦ä¿å­˜")
    print("   - æˆåŠŸçš„episodeæœƒè‡ªå‹•æç¤ºä¿å­˜")
    print("   - æŒ‰ Ctrl+C æŸ¥çœ‹çµ±è¨ˆä¿¡æ¯")
    
    try:
        # ä¸»è¦é™æ§å¾ªç’°
        while True:
            # é‡ç½®ç’°å¢ƒ
            observation, info = env.reset()
            collector.start_episode(observation, info)
            
            # Episodeå¾ªç’°
            terminated = truncated = False
            while not (terminated or truncated):
                # æª¢æŸ¥é€€å‡º
                if keyboard_controller.should_quit():
                    print("\n[INFO] ESC pressed â€” é€€å‡ºé™æ§")
                    collector.print_statistics()
                    env.close()
                    return
                
                # ç²å–éµç›¤è¼¸å…¥
                command = keyboard_controller.advance()
                ctrl, _ = lower_t1_robot.get_actions(command, observation, info)
                
                # åŸ·è¡Œå‹•ä½œ
                next_observation, reward, terminated, truncated, next_info = env.step(ctrl)
                
                # è¨˜éŒ„æ•¸æ“š
                collector.record_step(next_observation, ctrl, reward, next_info)
                
                observation = next_observation
                info = next_info
            
            # EpisodeçµæŸ
            success = info.get("success", False)
            collector.end_episode(success)
            
            # è©¢å•æ˜¯å¦ç¹¼çºŒ
            continue_choice = input("\nğŸ”„ ç¹¼çºŒä¸‹ä¸€å€‹episodeå—ï¼Ÿ[Y/n]: ").strip().lower()
            if continue_choice in ['n', 'no']:
                collector.print_statistics()
                break
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸ æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿ...")
        collector.print_statistics()
        
        # è©¢å•æ˜¯å¦ä¿å­˜
        if collector.all_trajectories:
            save_choice = input("ğŸ’¾ ä¿å­˜å·²æ”¶é›†çš„è»Œè·¡å—ï¼Ÿ[Y/n]: ").strip().lower()
            if save_choice in ['', 'y', 'yes']:
                collector.save_to_file()
    
    finally:
        env.close()
        print("ğŸ‰ å°ˆå®¶è»Œè·¡æ”¶é›†å®Œæˆï¼")


if __name__ == "__main__":
    parser = argparse.ArgumentParser("æ”¶é›†å°ˆå®¶è»Œè·¡ - æ‰‹å‹•é™æ§æ©Ÿå™¨äºº")
    parser.add_argument("--env", type=str, default="LowerT1GoaliePenaltyKick-v0", help="ç’°å¢ƒåç¨±")
    parser.add_argument("--pos_sensitivity", type=float, default=0.1, help="ä½ç½®æ•æ„Ÿåº¦")
    parser.add_argument("--rot_sensitivity", type=float, default=0.5, help="æ—‹è½‰æ•æ„Ÿåº¦")
    parser.add_argument("--renderer", type=str, default="mujoco", help="æ¸²æŸ“å™¨")
    
    args = parser.parse_args()
    
    expert_teleoperate(args.env, args.pos_sensitivity, args.rot_sensitivity, args.renderer)