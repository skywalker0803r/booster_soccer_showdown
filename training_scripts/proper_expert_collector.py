"""
æ­£ç¢ºçš„å°ˆå®¶è»Œè·¡æ”¶é›†å™¨
ä½¿ç”¨çœŸæ­£çš„æ©Ÿå™¨äººé‹å‹•å­¸æ§åˆ¶ï¼Œè€Œä¸æ˜¯ççŒœé—œç¯€æ˜ å°„
"""

import numpy as np
import pickle
import os
from datetime import datetime
import keyboard
from sai_rl import SAIClient
import time
import sys

# å˜—è©¦å°å…¥æ©Ÿå™¨äººæ§åˆ¶ç³»çµ±
try:
    # æ·»åŠ è·¯å¾‘
    current_dir = os.path.dirname(os.path.abspath(__file__))
    booster_control_path = os.path.join(os.path.dirname(current_dir), 'booster_control')
    sys.path.insert(0, booster_control_path)
    
    from t1_utils import LowerT1JoyStick
    ROBOT_CONTROL_AVAILABLE = True
    print("âœ… æˆåŠŸå°å…¥æ©Ÿå™¨äººæ§åˆ¶ç³»çµ±")
except Exception as e:
    print(f"âš ï¸ ç„¡æ³•å°å…¥æ©Ÿå™¨äººæ§åˆ¶ç³»çµ±: {e}")
    ROBOT_CONTROL_AVAILABLE = False


class RobotCommandGenerator:
    """æ©Ÿå™¨äººæŒ‡ä»¤ç”Ÿæˆå™¨"""
    
    def __init__(self):
        # åŸºç¤é‹å‹•å‘½ä»¤ (se3æ ¼å¼)
        self.base_command = np.zeros(6)  # [x, y, z, roll, pitch, yaw]
        self.movement_scale = 0.5  # é‹å‹•ç¸®æ”¾å› å­
        
        # å‘½ä»¤æ˜ å°„
        self.command_mapping = {
            # åŸºç¤ç§»å‹• (åœ¨æ©Ÿå™¨äººåº§æ¨™ç³»ä¸­)
            'move_forward': np.array([0.5, 0, 0, 0, 0, 0]),     # Xæ­£æ–¹å‘
            'move_backward': np.array([-0.5, 0, 0, 0, 0, 0]),   # Xè² æ–¹å‘
            'move_left': np.array([0, 0.3, 0, 0, 0, 0]),        # Yæ­£æ–¹å‘
            'move_right': np.array([0, -0.3, 0, 0, 0, 0]),      # Yè² æ–¹å‘
            'turn_left': np.array([0, 0, 0, 0, 0, 0.3]),        # é€†æ™‚é‡è½‰
            'turn_right': np.array([0, 0, 0, 0, 0, -0.3]),      # é †æ™‚é‡è½‰
            
            # è¤‡åˆå‹•ä½œ
            'forward_left': np.array([0.5, 0.2, 0, 0, 0, 0.1]), # å‰é€²+å·¦è½‰
            'forward_right': np.array([0.5, -0.2, 0, 0, 0, -0.1]), # å‰é€²+å³è½‰
            
            # é‡å¿ƒèª¿æ•´
            'lean_forward': np.array([0, 0, 0, 0, 0.1, 0]),     # å‘å‰å‚¾
            'lean_back': np.array([0, 0, 0, 0, -0.1, 0]),       # å‘å¾Œå‚¾
            'lean_left': np.array([0, 0, 0, 0.1, 0, 0]),        # å‘å·¦å‚¾
            'lean_right': np.array([0, 0, 0, -0.1, 0, 0]),      # å‘å³å‚¾
            
            # é«˜åº¦èª¿æ•´
            'stand_up': np.array([0, 0, 0.1, 0, 0, 0]),         # ç«™é«˜ä¸€é»
            'crouch_down': np.array([0, 0, -0.1, 0, 0, 0]),     # è¹²ä½ä¸€é»
        }
        
        print("ğŸ¤– æ©Ÿå™¨äººæŒ‡ä»¤ç”Ÿæˆå™¨åˆå§‹åŒ–")
        print("ğŸ“– å¯ç”¨æŒ‡ä»¤:")
        for cmd in self.command_mapping.keys():
            print(f"   {cmd}")
    
    def get_command(self, command_name, intensity=1.0):
        """ç²å–æ©Ÿå™¨äººæŒ‡ä»¤"""
        if command_name in self.command_mapping:
            return self.command_mapping[command_name] * intensity * self.movement_scale
        else:
            return np.zeros(6)


class ProperKeyboardController:
    """ä½¿ç”¨çœŸæ­£æ©Ÿå™¨äººæ§åˆ¶é‚è¼¯çš„éµç›¤æ§åˆ¶å™¨"""
    
    def __init__(self, env):
        self.env = env
        self.running = True
        self.pressed_keys = set()
        
        # æ©Ÿå™¨äººæ§åˆ¶ç³»çµ±
        if ROBOT_CONTROL_AVAILABLE:
            self.robot_controller = LowerT1JoyStick(env.unwrapped)
            print("âœ… ä½¿ç”¨çœŸæ­£çš„æ©Ÿå™¨äººæ§åˆ¶ç³»çµ±")
        else:
            self.robot_controller = None
            print("âŒ å›é€€åˆ°å‘½ä»¤ç”Ÿæˆå™¨")
        
        # æŒ‡ä»¤ç”Ÿæˆå™¨
        self.command_generator = RobotCommandGenerator()
        
        # æŒ‰éµåˆ°æŒ‡ä»¤æ˜ å°„
        self.key_to_command = {
            'w': 'move_forward',
            's': 'move_backward', 
            'a': 'turn_left',
            'd': 'turn_right',
            'q': 'move_left',
            'e': 'move_right',
            'r': 'lean_forward',
            'f': 'lean_back',
            't': 'stand_up',
            'g': 'crouch_down',
            'z': 'forward_left',
            'c': 'forward_right',
        }
        
        print("ğŸ® çœŸæ­£çš„æ©Ÿå™¨äººæ§åˆ¶å™¨åˆå§‹åŒ–")
        print("ğŸ“– æ§åˆ¶èªªæ˜:")
        print("   W/S: å‰é€²/å¾Œé€€")
        print("   A/D: å·¦è½‰/å³è½‰")
        print("   Q/E: æ©«å‘ç§»å‹•")
        print("   R/F: å‰å‚¾/å¾Œå‚¾")
        print("   T/G: ç«™é«˜/è¹²ä½")
        print("   Z/C: å‰é€²è½‰å½")
        print("   ESC: é€€å‡º")
    
    def start_keyboard_listener(self):
        """å•Ÿå‹•éµç›¤ç›£è½"""
        
        def on_key_press(event):
            if event.name == 'esc':
                print("ğŸšª ESCæŒ‰ä¸‹ï¼Œæº–å‚™é€€å‡º...")
                self.running = False
                return
            
            if event.name in self.key_to_command and event.name not in self.pressed_keys:
                self.pressed_keys.add(event.name)
                command_name = self.key_to_command[event.name]
                print(f"ğŸ® æŒ‰éµæŒ‰ä¸‹: {event.name} â†’ {command_name}")
        
        def on_key_release(event):
            if event.name in self.pressed_keys:
                self.pressed_keys.remove(event.name)
                print(f"ğŸ® æŒ‰éµé‡‹æ”¾: {event.name}")
        
        keyboard.on_press(on_key_press)
        keyboard.on_release(on_key_release)
        
        print("âœ… éµç›¤ç›£è½å·²å•Ÿå‹•")
    
    def get_robot_action(self, observation, info):
        """ç²å–æ©Ÿå™¨äººå‹•ä½œ - ä½¿ç”¨çœŸæ­£çš„æ§åˆ¶é‚è¼¯"""
        
        # åˆæˆSE3æŒ‡ä»¤
        combined_command = np.zeros(6)
        active_commands = []
        
        for key_name in self.pressed_keys:
            if key_name in self.key_to_command:
                command_name = self.key_to_command[key_name]
                command = self.command_generator.get_command(command_name)
                combined_command += command
                active_commands.append(command_name)
        
        if active_commands:
            print(f"ğŸ® æ´»å‹•æŒ‡ä»¤: {', '.join(active_commands)}")
            print(f"ğŸ“Š åˆæˆSE3æŒ‡ä»¤: {combined_command}")
        
        # ä½¿ç”¨æ©Ÿå™¨äººæ§åˆ¶å™¨è½‰æ›ç‚ºé—œç¯€å‹•ä½œ
        if self.robot_controller is not None:
            try:
                # ä½¿ç”¨çœŸæ­£çš„æ©Ÿå™¨äººæ§åˆ¶ç³»çµ±
                joint_action = self.robot_controller.get_actions(combined_command, observation, info)
                if isinstance(joint_action, tuple):
                    joint_action = joint_action[0]  # å–ç¬¬ä¸€å€‹å…ƒç´ 
                
                print(f"ğŸ¤– æ©Ÿå™¨äººé—œç¯€å‹•ä½œ: {joint_action}")
                return joint_action
                
            except Exception as e:
                print(f"âš ï¸ æ©Ÿå™¨äººæ§åˆ¶å™¨éŒ¯èª¤: {e}")
                # å›é€€åˆ°é›¶å‹•ä½œ
                return np.zeros(self.env.action_space.shape[0])
        else:
            # å¦‚æœæ²’æœ‰æ©Ÿå™¨äººæ§åˆ¶å™¨ï¼Œè¿”å›é›¶å‹•ä½œ
            return np.zeros(self.env.action_space.shape[0])


class ProperExpertCollector:
    """ä½¿ç”¨æ­£ç¢ºæ©Ÿå™¨äººæ§åˆ¶çš„å°ˆå®¶è»Œè·¡æ”¶é›†å™¨"""
    
    def __init__(self, save_dir="expert_data"):
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)
        
        # SAIç’°å¢ƒ
        print("ğŸ”„ åˆå§‹åŒ–SAIç’°å¢ƒ...")
        self.sai = SAIClient(comp_id="booster-soccer-showdown", api_key="sai_LFcuaCZiqEkUbNVolQ3wbk5yU7H11jfv")
        self.env = self.sai.make_env()
        
        # è¦–è¦ºåŒ–
        print("ğŸ¨ å•Ÿç”¨è¦–è¦ºåŒ–...")
        self.env.unwrapped.render_mode = "human"
        try:
            self.env.render()
            print("âœ… è¦–è¦ºåŒ–çª—å£å·²é–‹å•Ÿ")
        except Exception as e:
            print(f"âš ï¸ è¦–è¦ºåŒ–å•é¡Œ: {e}")
        
        # Preprocessor
        sys.path.append(os.path.dirname(os.path.abspath(__file__)))
        from main_improved_dreamerv3 import Preprocessor
        self.preprocessor = Preprocessor()
        
        # æ©Ÿå™¨äººæ§åˆ¶å™¨
        self.keyboard_controller = ProperKeyboardController(self.env)
        
        # æ•¸æ“šæ”¶é›†
        self.all_trajectories = []
        self.episode_count = 0
        
        print("âœ… æ­£ç¢ºçš„å°ˆå®¶æ”¶é›†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def collect_episode(self):
        """æ”¶é›†episode"""
        
        self.episode_count += 1
        print(f"\nğŸ® Episode {self.episode_count} é–‹å§‹...")
        
        # é‡ç½®ç’°å¢ƒ
        obs, info = self.env.reset()
        obs_processed = self.preprocessor.modify_state(obs, info).squeeze()
        
        # Episodeæ•¸æ“š
        episode_data = {
            'observations': [obs_processed],
            'actions': [],
            'rewards': [],
            'episode_reward': 0,
            'start_time': time.time()
        }
        
        # Episodeå¾ªç’°
        step = 0
        while self.keyboard_controller.running and step < 800:
            
            # ç²å–æ©Ÿå™¨äººå‹•ä½œï¼ˆä½¿ç”¨çœŸæ­£çš„æ§åˆ¶ç³»çµ±ï¼‰
            robot_action = self.keyboard_controller.get_robot_action(obs, info)
            
            # ç¢ºä¿å‹•ä½œç¶­åº¦æ­£ç¢º
            if robot_action.shape[0] != self.env.action_space.shape[0]:
                print(f"âš ï¸ å‹•ä½œç¶­åº¦ä¸åŒ¹é…: {robot_action.shape} vs {self.env.action_space.shape}")
                robot_action = np.zeros(self.env.action_space.shape[0])
            
            # åŸ·è¡Œå‹•ä½œ
            next_obs, reward, terminated, truncated, next_info = self.env.step(robot_action)
            next_obs_processed = self.preprocessor.modify_state(next_obs, next_info).squeeze()
            
            # è¨˜éŒ„æ•¸æ“š (è½‰æ›ç‚ºæ­¸ä¸€åŒ–å‹•ä½œä¾›BCä½¿ç”¨)
            normalized_action = 2 * (robot_action - self.env.action_space.low) / (self.env.action_space.high - self.env.action_space.low) - 1
            
            episode_data['actions'].append(normalized_action)
            episode_data['rewards'].append(reward)
            episode_data['episode_reward'] += reward
            episode_data['observations'].append(next_obs_processed)
            
            step += 1
            
            # å¯¦æ™‚ä¿¡æ¯
            if step % 100 == 0:
                print(f"   Step {step}, çå‹µ: {episode_data['episode_reward']:.3f}")
            
            if terminated or truncated:
                print(f"   Episodeåœ¨ç¬¬{step}æ­¥çµæŸ")
                break
            
            obs = next_obs
            info = next_info
            time.sleep(0.05)
        
        # EpisodeçµæŸ
        duration = time.time() - episode_data['start_time']
        reward = episode_data['episode_reward']
        
        print(f"\nğŸ“Š Episode {self.episode_count} çµæœ:")
        print(f"   çå‹µ: {reward:.3f}")
        print(f"   æ­¥æ•¸: {len(episode_data['actions'])}")
        print(f"   æ™‚é•·: {duration:.1f}ç§’")
        
        # ä¿å­˜æ±ºå®š
        if reward > -10:
            save_decision = input("ğŸ’¾ ä¿å­˜é€™å€‹episodeå—ï¼Ÿ[Y/n]: ").strip().lower()
            save_decision = save_decision in ['', 'y', 'yes']
        else:
            save_decision = input("ğŸ˜ è¡¨ç¾è¼ƒå·®ï¼Œä»è¦ä¿å­˜å—ï¼Ÿ[y/N]: ").strip().lower() 
            save_decision = save_decision in ['y', 'yes']
        
        if save_decision:
            self._save_episode(episode_data)
        
        return episode_data if save_decision else None
    
    def _save_episode(self, episode_data):
        """ä¿å­˜episode"""
        
        trajectory = {
            'observations': np.array(episode_data['observations'][:-1]),
            'actions': np.array(episode_data['actions']),
            'rewards': np.array(episode_data['rewards']),
            'episode_reward': episode_data['episode_reward'],
            'collection_time': datetime.now().isoformat(),
            'episode_id': self.episode_count
        }
        
        self.all_trajectories.append(trajectory)
        
        # ä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"proper_expert_trajectories_{timestamp}.pkl"
        filepath = os.path.join(self.save_dir, filename)
        
        with open(filepath, 'wb') as f:
            pickle.dump(self.all_trajectories, f)
        
        # BCæ¨™æº–æ ¼å¼
        standard_path = os.path.join(self.save_dir, "expert_trajectories.pkl")
        with open(standard_path, 'wb') as f:
            pickle.dump(self.all_trajectories, f)
        
        print(f"âœ… Episodeå·²ä¿å­˜ï¼ç¸½è»Œè·¡æ•¸: {len(self.all_trajectories)}")
    
    def run_collection(self):
        """é‹è¡Œæ”¶é›†"""
        
        print("ğŸš€ é–‹å§‹æ­£ç¢ºçš„å°ˆå®¶è»Œè·¡æ”¶é›†")
        print("="*60)
        
        self.keyboard_controller.start_keyboard_listener()
        
        try:
            while self.keyboard_controller.running:
                episode = self.collect_episode()
                
                if not self.keyboard_controller.running:
                    break
                
                continue_choice = input("\nğŸ”„ æ”¶é›†ä¸‹ä¸€å€‹episodeå—ï¼Ÿ[Y/n]: ").strip().lower()
                if continue_choice in ['n', 'no']:
                    break
        
        except KeyboardInterrupt:
            print("\nâš ï¸ æ”¶é›†ä¸­æ–·")
        
        finally:
            keyboard.unhook_all()
            self.env.close()
            
            if self.all_trajectories:
                rewards = [t['episode_reward'] for t in self.all_trajectories]
                print(f"\nğŸ“Š æ”¶é›†çµ±è¨ˆ:")
                print(f"   ç¸½è»Œè·¡æ•¸: {len(self.all_trajectories)}")
                print(f"   å¹³å‡çå‹µ: {np.mean(rewards):.3f}")
                print(f"   æœ€ä½³çå‹µ: {max(rewards):.3f}")
                print("\nğŸ’¡ ç¾åœ¨å¯ä»¥é‹è¡Œ behavioral_cloning.py")


if __name__ == "__main__":
    print("ğŸ¤– æ­£ç¢ºçš„æ©Ÿå™¨äººæ§åˆ¶å°ˆå®¶è»Œè·¡æ”¶é›†å™¨")
    print("ğŸ’¡ ä½¿ç”¨çœŸæ­£çš„æ©Ÿå™¨äººé‹å‹•å­¸æ§åˆ¶ç³»çµ±")
    
    if not ROBOT_CONTROL_AVAILABLE:
        print("âš ï¸ è­¦å‘Š: ç„¡æ³•ä½¿ç”¨æ©Ÿå™¨äººæ§åˆ¶ç³»çµ±ï¼ŒåŠŸèƒ½å—é™")
        choice = input("æ˜¯å¦ç¹¼çºŒï¼Ÿ[y/N]: ").strip().lower()
        if choice not in ['y', 'yes']:
            exit(1)
    
    try:
        collector = ProperExpertCollector()
        collector.run_collection()
    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()