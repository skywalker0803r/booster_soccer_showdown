{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec3e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭──────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">      ########      ###     ###########</span>                              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">    #+#    #+#   #+# #+#       #+#</span>                                   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">   +#+         +#+   +#+      +#+</span>                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">  +########+ +#########+     +#+</span>                                     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">        +#+ +#+     +#+     +#+</span>                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">#+#    #+# #+#     #+#     #+#</span>                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">########  ###     ### ###########</span>                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0; font-weight: bold\">v0.1.35</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">© 2025 ArenaX Labs</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭──────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                             \u001b[1;37m      ########      ###     ###########\u001b[0m                              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                             \u001b[1;37m    #+#    #+#   #+# #+#       #+#\u001b[0m                                   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                             \u001b[1;37m   +#+         +#+   +#+      +#+\u001b[0m                                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                             \u001b[1;37m  +########+ +#########+     +#+\u001b[0m                                     \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                             \u001b[1;37m        +#+ +#+     +#+     +#+\u001b[0m                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                             \u001b[1;37m#+#    #+# #+#     #+#     #+#\u001b[0m                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                             \u001b[1;37m########  ###     ### ###########\u001b[0m                                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                         \u001b[1;37mv0.1.35\u001b[0m  \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                              \u001b[2m© 2025 ArenaX Labs\u001b[0m  \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✓ Successfully imported sai-mujoco package.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m✓ Successfully imported sai-mujoco package.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭─ </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Competition Tasks</span><span style=\"color: #008080; text-decoration-color: #008080\"> ──────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                  <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">      Task    Environment                                      Score Weight           Episodes  </span> <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">         0  </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  Penalty Kick with Goalie (Lower T1)                       1.0  </span><span style=\"color: #008000; text-decoration-color: #008000\">              100  </span> <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">            </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  </span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">(LowerT1GoaliePenaltyKick-v0)</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                  </span><span style=\"color: #008000; text-decoration-color: #008000\">                   </span> <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">         1  </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  Penalty Kick with Obstacles (Lower T1)                    1.0  </span><span style=\"color: #008000; text-decoration-color: #008000\">              100  </span> <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">            </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  </span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">(LowerT1ObstaclePenaltyKick-v0)</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                </span><span style=\"color: #008000; text-decoration-color: #008000\">                   </span> <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">         2  </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  Kick to Target (Lower T1)                                 1.0  </span><span style=\"color: #008000; text-decoration-color: #008000\">              100  </span> <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">            </span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  </span><span style=\"color: #dfdfdf; text-decoration-color: #dfdfdf\">(LowerT1KickToTarget-v0)</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                       </span><span style=\"color: #008000; text-decoration-color: #008000\">                   </span> <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                  <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m╭─\u001b[0m\u001b[36m \u001b[0m\u001b[1;36mCompetition Tasks\u001b[0m\u001b[36m \u001b[0m\u001b[36m─────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[36m─╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                  \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m \u001b[1;35m  \u001b[0m\u001b[1;35m    Task\u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35mEnvironment                               \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m   Score Weight\u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m       Episodes\u001b[0m\u001b[1;35m  \u001b[0m \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m \u001b[1;36m  \u001b[0m\u001b[1;36m       \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;36m  \u001b[0m\u001b[37m  \u001b[0m\u001b[37mPenalty Kick with Goalie (Lower T1)       \u001b[0m\u001b[37m  \u001b[0m\u001b[37m  \u001b[0m\u001b[37m            1.0\u001b[0m\u001b[37m  \u001b[0m\u001b[32m  \u001b[0m\u001b[32m            100\u001b[0m\u001b[32m  \u001b[0m \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m \u001b[1;36m            \u001b[0m\u001b[37m  \u001b[0m\u001b[2;37m(LowerT1GoaliePenaltyKick-v0)\u001b[0m\u001b[37m             \u001b[0m\u001b[37m  \u001b[0m\u001b[37m                   \u001b[0m\u001b[32m                   \u001b[0m \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m \u001b[1;36m  \u001b[0m\u001b[1;36m       \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;36m  \u001b[0m\u001b[37m  \u001b[0m\u001b[37mPenalty Kick with Obstacles (Lower T1)    \u001b[0m\u001b[37m  \u001b[0m\u001b[37m  \u001b[0m\u001b[37m            1.0\u001b[0m\u001b[37m  \u001b[0m\u001b[32m  \u001b[0m\u001b[32m            100\u001b[0m\u001b[32m  \u001b[0m \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m \u001b[1;36m            \u001b[0m\u001b[37m  \u001b[0m\u001b[2;37m(LowerT1ObstaclePenaltyKick-v0)\u001b[0m\u001b[37m           \u001b[0m\u001b[37m  \u001b[0m\u001b[37m                   \u001b[0m\u001b[32m                   \u001b[0m \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m \u001b[1;36m  \u001b[0m\u001b[1;36m       \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;36m  \u001b[0m\u001b[37m  \u001b[0m\u001b[37mKick to Target (Lower T1)                 \u001b[0m\u001b[37m  \u001b[0m\u001b[37m  \u001b[0m\u001b[37m            1.0\u001b[0m\u001b[37m  \u001b[0m\u001b[32m  \u001b[0m\u001b[32m            100\u001b[0m\u001b[32m  \u001b[0m \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m \u001b[1;36m            \u001b[0m\u001b[37m  \u001b[0m\u001b[2;37m(LowerT1KickToTarget-v0)\u001b[0m\u001b[37m                  \u001b[0m\u001b[37m  \u001b[0m\u001b[37m                   \u001b[0m\u001b[32m                   \u001b[0m \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                  \u001b[36m│\u001b[0m\n",
       "\u001b[36m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 環境資訊 ---\n",
      "Observation Space: Box(-inf, inf, (45,), float32)\n",
      "Action Space: Box([-45. -45. -30. -65. -24. -15. -45. -45. -30. -65. -24. -15.], [45. 45. 30. 65. 24. 15. 45. 45. 30. 65. 24. 15.], (12,), float32)\n",
      "Evaluation Function: <function evaluation_fn at 0x0000014FE3EAEC20>\n",
      "--- 開始執行隨機策略循環 ---\n",
      "Step: 001 | Action (Shape: (12,)): [-22.839008 -12.50071 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.00466053 -0.00028957  0.0002023   0.00719183 -0.00877619]\n",
      "Step: 002 | Action (Shape: (12,)): [ 5.574111  -3.1028745] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.00854897 -0.00064581  0.00015355  0.01250538 -0.01256074]\n",
      "Step: 003 | Action (Shape: (12,)): [ 37.505146 -27.596138] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.0077301  -0.00088937  0.00679459  0.01078899 -0.01356455]\n",
      "Step: 004 | Action (Shape: (12,)): [23.186747 33.541695] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.00497826 -0.00030569  0.00743002  0.00568312 -0.01403812]\n",
      "Step: 005 | Action (Shape: (12,)): [ 38.295063 -38.98645 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.00219156 -0.00011049  0.01505132  0.00304167 -0.01799532]\n",
      "Step: 006 | Action (Shape: (12,)): [27.269096 28.95956 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 0.00485545  0.00028218  0.02396579 -0.0067459  -0.01710615]\n",
      "Step: 007 | Action (Shape: (12,)): [ 34.358387 -25.706297] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 0.01281622  0.00011919  0.02924181 -0.01486172 -0.02750991]\n",
      "Step: 008 | Action (Shape: (12,)): [-34.773254   4.72528 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 1.9703401e-02  3.1626456e-05  4.0231805e-02 -2.1319097e-02\n",
      " -4.9323503e-02]\n",
      "Step: 009 | Action (Shape: (12,)): [ 7.4222755 -9.325001 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 0.02495788  0.00011832  0.05028681 -0.02384809 -0.06100951]\n",
      "Step: 010 | Action (Shape: (12,)): [ 15.61187  -31.890205] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 3.0967934e-02 -9.2683304e-06  5.8681700e-02 -2.5629895e-02\n",
      " -8.5678756e-02]\n",
      "Step: 011 | Action (Shape: (12,)): [-2.1149874 44.21865  ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 0.03421158  0.00073914  0.07468092 -0.02121822 -0.12004804]\n",
      "Step: 012 | Action (Shape: (12,)): [32.456413 38.36944 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 0.03731793  0.00237782  0.08968753 -0.01756618 -0.14610834]\n",
      "Step: 013 | Action (Shape: (12,)): [-21.419458   6.129234] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 0.0381558   0.00449423  0.1087779  -0.01064383 -0.17470399]\n",
      "Step: 014 | Action (Shape: (12,)): [-13.189681 -27.01686 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 0.03790478  0.0069041   0.12710702 -0.00261186 -0.19825768]\n",
      "Step: 015 | Action (Shape: (12,)): [ -9.644612 -15.955742] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 0.03769536  0.00898093  0.13973075  0.00366397 -0.2087354 ]\n",
      "Step: 016 | Action (Shape: (12,)): [-5.608242 -5.33716 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 0.03393878  0.01054025  0.14918658  0.01443207 -0.21763614]\n",
      "Step: 017 | Action (Shape: (12,)): [-29.160103    3.0747638] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 0.0271181   0.01229715  0.15645322  0.02928113 -0.22501147]\n",
      "Step: 018 | Action (Shape: (12,)): [-17.078978 -11.674688] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 0.02068805  0.01265379  0.15775199  0.04138753 -0.22119546]\n",
      "Step: 019 | Action (Shape: (12,)): [-21.077831  25.72109 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 0.01554703  0.01282944  0.15441716  0.05046681 -0.21227562]\n",
      "Step: 020 | Action (Shape: (12,)): [ 0.25065374 12.9721    ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [ 0.0087973   0.01362948  0.15065256  0.06167921 -0.20218666]\n",
      "Step: 021 | Action (Shape: (12,)): [-11.150861 -44.947433] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.00153054  0.01394931  0.14184758  0.0779915  -0.19147676]\n",
      "Step: 022 | Action (Shape: (12,)): [ 1.8897265 25.186285 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.0107003   0.01433686  0.13109598  0.09276648 -0.17962681]\n",
      "Step: 023 | Action (Shape: (12,)): [40.13319  30.282637] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.0178318   0.01545984  0.1230112   0.10663231 -0.1701558 ]\n",
      "Step: 024 | Action (Shape: (12,)): [32.871365 35.906036] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.02089691  0.01649439  0.10809478  0.11322074 -0.14727676]\n",
      "Step: 025 | Action (Shape: (12,)): [23.94233  19.632923] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.02148276  0.01818138  0.09940194  0.11615898 -0.12273384]\n",
      "Step: 026 | Action (Shape: (12,)): [-22.627754  16.95946 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.02338463  0.01984071  0.08482264  0.11994438 -0.0957438 ]\n",
      "Step: 027 | Action (Shape: (12,)): [-15.109722   9.937761] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.02653193  0.02229555  0.07432778  0.124539   -0.05684343]\n",
      "Step: 028 | Action (Shape: (12,)): [19.290295 12.654888] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.02672725  0.02514148  0.06737671  0.12232058 -0.00397056]\n",
      "Step: 029 | Action (Shape: (12,)): [-41.37832  -22.855648] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.03148462  0.02863254  0.06276881  0.12764189  0.03522975]\n",
      "Step: 030 | Action (Shape: (12,)): [-39.102085 -43.929543] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.03853064  0.03122699  0.06225075  0.1374294   0.05838353]\n",
      "Step: 031 | Action (Shape: (12,)): [-27.535522 -39.866806] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.04474389  0.03254508  0.0572287   0.14593124  0.06874882]\n",
      "Step: 032 | Action (Shape: (12,)): [-3.4561017 29.27037  ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.05154355  0.03496246  0.05466143  0.15603358  0.06876411]\n",
      "Step: 033 | Action (Shape: (12,)): [-18.14724  -34.711365] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.06000534  0.03666365  0.04945328  0.16863464  0.06048018]\n",
      "Step: 034 | Action (Shape: (12,)): [-13.636437    6.6808105] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.06900071  0.03860184  0.04303565  0.18195125  0.04759337]\n",
      "Step: 035 | Action (Shape: (12,)): [ 20.627213 -33.65575 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.07968666  0.04013522  0.03451408  0.1997268   0.02641662]\n",
      "Step: 036 | Action (Shape: (12,)): [-36.89042  -8.60548] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.09497319  0.04216814  0.02988356  0.22353801  0.00269104]\n",
      "Step: 037 | Action (Shape: (12,)): [-15.638165  30.070265] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.1081524   0.04489623  0.0308008   0.24303874 -0.02736069]\n",
      "Step: 038 | Action (Shape: (12,)): [-7.8288956 14.011953 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.11882185  0.04803766  0.03130207  0.25878    -0.0546151 ]\n",
      "Step: 039 | Action (Shape: (12,)): [-12.835666  19.010677] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.13417448  0.05170264  0.03120937  0.28034517 -0.08035081]\n",
      "Step: 040 | Action (Shape: (12,)): [ -8.338091 -17.058748] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.15392703  0.05572139  0.03118093  0.30777082 -0.10537156]\n",
      "Step: 041 | Action (Shape: (12,)): [ 10.446816 -43.988613] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.1736925   0.05933426  0.02976347  0.33666536 -0.13198604]\n",
      "Step: 042 | Action (Shape: (12,)): [-25.437365  29.42761 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.19797462  0.06333677  0.02491816  0.3719361  -0.16422595]\n",
      "Step: 043 | Action (Shape: (12,)): [-20.502201 -19.836468] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.22109056  0.06515983  0.01526678  0.40347645 -0.1946725 ]\n",
      "Step: 044 | Action (Shape: (12,)): [-29.119307 -41.318436] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.24905229  0.06623156  0.00360744  0.44186583 -0.2214024 ]\n",
      "Step: 045 | Action (Shape: (12,)): [41.786255  -0.6050326] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.27507165  0.06923172 -0.00370533  0.4773874  -0.24247156]\n",
      "Step: 046 | Action (Shape: (12,)): [-14.14099  -29.757942] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.2995282   0.07326506 -0.00851509  0.5111794  -0.26104498]\n",
      "Step: 047 | Action (Shape: (12,)): [ 3.2401562 34.1446   ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.32414034  0.07905917 -0.00996938  0.5454219  -0.27886227]\n",
      "Step: 048 | Action (Shape: (12,)): [-21.657148 -32.66716 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.34817186  0.08587055 -0.00877609  0.57789904 -0.2940195 ]\n",
      "Step: 049 | Action (Shape: (12,)): [ 36.289597 -39.325104] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.36842534  0.09213392 -0.00742127  0.605486   -0.30537242]\n",
      "Step: 050 | Action (Shape: (12,)): [ 3.0896027 39.22139  ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.3851176   0.10166886  0.00097947  0.62646854 -0.30459684]\n",
      "Step: 051 | Action (Shape: (12,)): [1.174759 3.497656] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.39829588  0.11284842  0.01420363  0.64139    -0.292988  ]\n",
      "Step: 052 | Action (Shape: (12,)): [-2.1147318 -3.2355528] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.41387832  0.12366574  0.02335866  0.6600816  -0.28567752]\n",
      "Step: 053 | Action (Shape: (12,)): [ 5.294282 32.344643] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.42874795  0.134501    0.0315017   0.678947   -0.28297743]\n",
      "Step: 054 | Action (Shape: (12,)): [26.408703 10.20171 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.44308615  0.14406216  0.03931315  0.6980117  -0.2709171 ]\n",
      "Step: 055 | Action (Shape: (12,)): [14.0482025  6.6030087] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.4581106   0.15500608  0.05075371  0.71963835 -0.26221362]\n",
      "Step: 056 | Action (Shape: (12,)): [-25.291395   3.064558] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.47284204  0.16574803  0.05965495  0.73929197 -0.24285321]\n",
      "Step: 057 | Action (Shape: (12,)): [8.849735  1.4303229] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.4849444   0.17552853  0.06781937  0.75516546 -0.22955717]\n",
      "Step: 058 | Action (Shape: (12,)): [-23.396946  24.742762] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.49797207  0.18473808  0.07599273  0.7704065  -0.21885268]\n",
      "Step: 059 | Action (Shape: (12,)): [ 37.272465 -25.019262] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.5106928   0.19339158  0.0841686   0.788412   -0.21823034]\n",
      "Step: 060 | Action (Shape: (12,)): [-42.852592 -10.678995] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.5226011   0.2006736   0.09056028  0.80272835 -0.22370313]\n",
      "Step: 061 | Action (Shape: (12,)): [-22.113068 -27.94762 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.5376721   0.20665212  0.09228873  0.8205413  -0.22639696]\n",
      "Step: 062 | Action (Shape: (12,)): [ 19.5265  -12.86099] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.55200255  0.21173231  0.09257863  0.83621407 -0.22527109]\n",
      "Step: 063 | Action (Shape: (12,)): [ 31.39632  -42.301723] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.56610155  0.21649371  0.09358012  0.8538363  -0.21345043]\n",
      "Step: 064 | Action (Shape: (12,)): [-15.684119  20.004004] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.58276385  0.2226662   0.09550422  0.8762838  -0.20448546]\n",
      "Step: 065 | Action (Shape: (12,)): [-24.20152  -19.118483] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.59823346  0.22789313  0.09613431  0.8953224  -0.18725233]\n",
      "Step: 066 | Action (Shape: (12,)): [-8.209487  2.235985] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.61493486  0.2318628   0.09327107  0.9155539  -0.17714827]\n",
      "Step: 067 | Action (Shape: (12,)): [-21.11014  32.02985] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.6327288   0.238442    0.09374684  0.9382445  -0.17089972]\n",
      "Step: 068 | Action (Shape: (12,)): [ 27.093649 -15.04829 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.65002674  0.24544708  0.09480338  0.961845   -0.16740799]\n",
      "Step: 069 | Action (Shape: (12,)): [-15.426661  37.694527] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.66940093  0.25332344  0.09574767  0.9877369  -0.1570362 ]\n",
      "Step: 070 | Action (Shape: (12,)): [  1.9564047 -11.812697 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.6867836   0.2592994   0.09437227  1.0084012  -0.13440941]\n",
      "Step: 071 | Action (Shape: (12,)): [-11.729814 -38.786404] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.7054081   0.26335093  0.08941349  1.0320272  -0.12065904]\n",
      "Step: 072 | Action (Shape: (12,)): [-34.299713  11.821237] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.72538763  0.26910824  0.08695483  1.0575505  -0.10909444]\n",
      "Step: 073 | Action (Shape: (12,)): [28.915302 40.618572] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.74572366  0.27591348  0.08432906  1.0864859  -0.10937523]\n",
      "Step: 074 | Action (Shape: (12,)): [-2.1767783  8.581618 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.7671488   0.2830425   0.07996784  1.1189309  -0.11806325]\n",
      "Step: 075 | Action (Shape: (12,)): [-18.734678  20.30565 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.78778994  0.2911616   0.07595226  1.1502801  -0.13773106]\n",
      "Step: 076 | Action (Shape: (12,)): [-26.68894   34.793747] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.80696356  0.30091593  0.07415164  1.1781588  -0.15562777]\n",
      "Step: 077 | Action (Shape: (12,)): [-38.647934  23.244526] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.8275485   0.31113663  0.07018536  1.2052735  -0.16328935]\n",
      "Step: 078 | Action (Shape: (12,)): [11.752127 43.196674] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.84738     0.3219928   0.0656473   1.2324653  -0.16921842]\n",
      "Step: 079 | Action (Shape: (12,)): [19.750456 -8.627444] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.86593485  0.3323002   0.06140556  1.2580376  -0.18439642]\n",
      "Step: 080 | Action (Shape: (12,)): [-16.853804  11.246595] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.88717663  0.34318346  0.05561898  1.2875825  -0.20323727]\n",
      "Step: 081 | Action (Shape: (12,)): [-2.3243196  -0.76655346] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.90967035  0.35423592  0.0488574   1.3182821  -0.22389972]\n",
      "Step: 082 | Action (Shape: (12,)): [31.14846  12.858241] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.93168074  0.36621246  0.04206536  1.3505865  -0.25663906]\n",
      "Step: 083 | Action (Shape: (12,)): [-19.97719 -10.75987] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.9530007   0.3783367   0.03556523  1.3810732  -0.29893428]\n",
      "Step: 084 | Action (Shape: (12,)): [-14.746244  41.16779 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.9744392   0.39244846  0.02953592  1.4113089  -0.33092734]\n",
      "Step: 085 | Action (Shape: (12,)): [-24.858816   9.44651 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-0.99896944  0.40608522  0.02113001  1.445547   -0.37653786]\n",
      "Step: 086 | Action (Shape: (12,)): [-10.775493  26.424938] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.0244657   0.42073673  0.01211324  1.4810188  -0.43454584]\n",
      "Step: 087 | Action (Shape: (12,)): [ 18.909119 -38.916054] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.0490457e+00  4.3235278e-01  3.4917317e-05  1.5122825e+00\n",
      " -4.8115209e-01]\n",
      "Step: 088 | Action (Shape: (12,)): [21.741991 18.28123 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.0728204   0.44508794 -0.01177569  1.5419394  -0.51943916]\n",
      "Step: 089 | Action (Shape: (12,)): [38.343674 43.129276] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.0934434   0.46095747 -0.02087026  1.5672541  -0.5472053 ]\n",
      "Step: 090 | Action (Shape: (12,)): [ 8.676885 -8.036648] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.1143342   0.47568613 -0.03197841  1.5920256  -0.568138  ]\n",
      "Step: 091 | Action (Shape: (12,)): [-7.5923696 -7.5971417] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.1350408   0.4895131  -0.04506567  1.6156803  -0.59689766]\n",
      "Step: 092 | Action (Shape: (12,)): [18.657356  9.521902] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.1555338   0.5032397  -0.05706042  1.6399821  -0.6226892 ]\n",
      "Step: 093 | Action (Shape: (12,)): [43.17554 31.09761] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.1740246   0.5181252  -0.06783704  1.6652043  -0.65041095]\n",
      "Step: 094 | Action (Shape: (12,)): [-19.995281  23.043518] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.1934057   0.532518   -0.07893763  1.6916068  -0.6831764 ]\n",
      "Step: 095 | Action (Shape: (12,)): [-1.0113853 43.142406 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.2111474   0.5478589  -0.08963192  1.7159253  -0.7236155 ]\n",
      "Step: 096 | Action (Shape: (12,)): [20.420872 34.08874 ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.2262189   0.5648265  -0.09829443  1.7372694  -0.7532002 ]\n",
      "Step: 097 | Action (Shape: (12,)): [-6.24277  41.410557] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.2413863   0.5825323  -0.10663727  1.7575873  -0.78209317]\n",
      "Step: 098 | Action (Shape: (12,)): [ 4.927251 42.555832] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.2559966   0.6023796  -0.11414773  1.7795455  -0.81541896]\n",
      "Step: 099 | Action (Shape: (12,)): [-15.868672 -25.189814] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.2717574   0.62088466 -0.12217026  1.8041074  -0.860528  ]\n",
      "Step: 100 | Action (Shape: (12,)): [ -0.11881674 -43.072834  ] | Reward: 0.0000 | Done: False\n",
      "Observation (Shape: (45,)): [-1.2862974   0.63641936 -0.13135315  1.8266758  -0.9164049 ]\n",
      "\n",
      "--- 隨機策略循環結束 ---\n"
     ]
    }
   ],
   "source": [
    "from sai_rl import SAIClient\n",
    "import numpy as np\n",
    "\n",
    "# 1. 初始化 SAIClient 和環境\n",
    "comp_id = \"booster-soccer-showdown\" # ⚠️ 請替換為您的比賽 ID\n",
    "api_key = \"sai_LFcuaCZiqEkUbNVolQ3wbk5yU7H11jfv\" # ⚠️ 請替換為您的 API Key\n",
    "sai = SAIClient(\n",
    "    comp_id=comp_id, \n",
    "    api_key=api_key,\n",
    ")\n",
    "env = sai.make_env()\n",
    "\n",
    "print(\"--- 環境資訊 ---\")\n",
    "print(f\"Observation Space: {env.observation_space}\")\n",
    "print(f\"Action Space: {env.action_space}\")\n",
    "print(f\"Evaluation Function: {env.evaluation_fn}\")\n",
    "print(\"--- 開始執行隨機策略循環 ---\")\n",
    "\n",
    "# 2. 執行隨機策略循環\n",
    "# 初始化環境\n",
    "obs, info = env.reset() # 注意：現在 gym/SAIClient 可能返回 (observation, info) 兩個值\n",
    "\n",
    "# 設定執行的步數\n",
    "max_steps = 100 \n",
    "\n",
    "for step in range(max_steps):\n",
    "    action = env.action_space.sample()\n",
    "    result = env.step(action)\n",
    "    obs, reward, terminated, truncated, info = result\n",
    "    done = terminated or truncated # 任何一個為 True 都表示回合結束\n",
    "    print(f\"Step: {step+1:03d} | Action (Shape: {action.shape}): {action[:2]} | Reward: {reward:.4f} | Done: {done}\")\n",
    "    print(f\"Observation (Shape: {obs.shape}): {obs[:5]}\") # 可以選擇打印部分觀察值\n",
    "    if done:\n",
    "        print(f\"\\n✅ 回合結束 (Terminated: {terminated}, Truncated: {truncated})，總步數: {step+1}\")\n",
    "        # 如果是多回合訓練，這裡會呼叫 env.reset() 進入下一回合\n",
    "        # obs, info = env.reset()\n",
    "        break # 為了範例簡潔，我們只跑一回合\n",
    "# 3. 關閉環境 (建議習慣)\n",
    "env.close()\n",
    "print(\"\\n--- 隨機策略循環結束 ---\")\n",
    "\n",
    "✓ Successfully imported sai-mujoco package.\n",
    "╭─ Competition Tasks ──────────────────────────────────────────────────────────────────────────────╮\n",
    "│                                                                                                  │\n",
    "│       Task    Environment                                      Score Weight           Episodes   │\n",
    "│          0    Penalty Kick with Goalie (Lower T1)                       1.0                100   │\n",
    "│               (LowerT1GoaliePenaltyKick-v0)                                                      │\n",
    "│          1    Penalty Kick with Obstacles (Lower T1)                    1.0                100   │\n",
    "│               (LowerT1ObstaclePenaltyKick-v0)                                                    │\n",
    "│          2    Kick to Target (Lower T1)                                 1.0                100   │\n",
    "│               (LowerT1KickToTarget-v0)                                                           │\n",
    "│                                                                                                  │\n",
    "╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
    "--- 環境資訊 ---\n",
    "Observation Space: Box(-inf, inf, (45,), float32)\n",
    "Action Space: Box([-45. -45. -30. -65. -24. -15. -45. -45. -30. -65. -24. -15.], [45. 45. 30. 65. 24. 15. 45. 45. 30. 65. 24. 15.], (12,), float32)\n",
    "Evaluation Function: <function evaluation_fn at 0x0000014FE3EAEC20>\n",
    "--- 開始執行隨機策略循環 ---\n",
    "Step: 001 | Action (Shape: (12,)): [-22.839008 -12.50071 ] | Reward: 0.0000 | Done: False\n",
    "Observation (Shape: (45,)): [-0.00466053 -0.00028957  0.0002023   0.00719183 -0.00877619]\n",
    "Step: 002 | Action (Shape: (12,)): [ 5.574111  -3.1028745] | Reward: 0.0000 | Done: False\n",
    "Observation (Shape: (45,)): [-0.00854897 -0.00064581  0.00015355  0.01250538 -0.01256074]\n",
    "Step: 003 | Action (Shape: (12,)): [ 37.505146 -27.596138] | Reward: 0.0000 | Done: False\n",
    "Observation (Shape: (45,)): [-0.0077301  -0.00088937  0.00679459  0.01078899 -0.01356455]\n",
    "Step: 004 | Action (Shape: (12,)): [23.186747 33.541695] | Reward: 0.0000 | Done: False\n",
    "Observation (Shape: (45,)): [-0.00497826 -0.00030569  0.00743002  0.00568312 -0.01403812]\n",
    "Step: 005 | Action (Shape: (12,)): [ 38.295063 -38.98645 ] | Reward: 0.0000 | Done: False\n",
    "Observation (Shape: (45,)): [-0.00219156 -0.00011049  0.01505132  0.00304167 -0.01799532]\n",
    "Step: 006 | Action (Shape: (12,)): [27.269096 28.95956 ] | Reward: 0.0000 | Done: False\n",
    "Observation (Shape: (45,)): [ 0.00485545  0.00028218  0.02396579 -0.0067459  -0.01710615]\n",
    "Step: 007 | Action (Shape: (12,)): [ 34.358387 -25.706297] | Reward: 0.0000 | Done: False\n",
    "Observation (Shape: (45,)): [ 0.01281622  0.00011919  0.02924181 -0.01486172 -0.02750991]\n",
    "Step: 008 | Action (Shape: (12,)): [-34.773254   4.72528 ] | Reward: 0.0000 | Done: False\n",
    "Observation (Shape: (45,)): [ 1.9703401e-02  3.1626456e-05  4.0231805e-02 -2.1319097e-02\n",
    " -4.9323503e-02]\n",
    "Step: 009 | Action (Shape: (12,)): [ 7.4222755 -9.325001 ] | Reward: 0.0000 | Done: False\n",
    "Observation (Shape: (45,)): [ 0.02495788  0.00011832  0.05028681 -0.02384809 -0.06100951]\n",
    "Step: 010 | Action (Shape: (12,)): [ 15.61187  -31.890205] | Reward: 0.0000 | Done: False\n",
    "...\n",
    "Step: 100 | Action (Shape: (12,)): [ -0.11881674 -43.072834  ] | Reward: 0.0000 | Done: False\n",
    "Observation (Shape: (45,)): [-1.2862974   0.63641936 -0.13135315  1.8266758  -0.9164049 ]\n",
    "\n",
    "--- 隨機策略循環結束 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19805e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d8ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7116007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vedanta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
