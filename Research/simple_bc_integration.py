"""
ç°¡åŒ–ç‰ˆBCæ•´åˆï¼šç‚ºæ‚¨ç¾æœ‰çš„main.pyæ·»åŠ å°ˆå®¶æ•¸æ“šé è¨“ç·´åŠŸèƒ½
åªéœ€æœ€å°ä¿®æ”¹å³å¯æ•´åˆåˆ°æ‚¨ç¾æœ‰çš„Research/main.py
"""

import numpy as np
import torch
import torch.nn as nn
import os

class ExpertDataLoader:
    """å°ˆå®¶æ•¸æ“šè¼‰å…¥å’Œæ ¼å¼è½‰æ›å™¨"""
    
    def __init__(self, expert_data_path):
        self.expert_data_path = expert_data_path
        self.expert_data = self._load_and_convert_data()
    
    def _load_and_convert_data(self):
        """è¼‰å…¥ä¸¦è½‰æ›å°ˆå®¶æ•¸æ“šæ ¼å¼"""
        if not os.path.exists(self.expert_data_path):
            print(f"âŒ å°ˆå®¶æ•¸æ“šä¸å­˜åœ¨: {self.expert_data_path}")
            return None
            
        print(f"ğŸ“š è¼‰å…¥å°ˆå®¶æ•¸æ“š: {self.expert_data_path}")
        data = np.load(self.expert_data_path, allow_pickle=True)
        
        il_observations = data['observations']  # 89ç¶­
        expert_actions = data['actions']       # 12ç¶­
        
        # ç°¡åŒ–è½‰æ›ï¼šå¾89ç¶­æå–45ç¶­
        # åŸºæ–¼IL preprocessorçš„çµæ§‹ï¼šå‰42ç¶­æ˜¯æ©Ÿå™¨äººç‹€æ…‹ï¼Œå¾Œ3ç¶­æ˜¯ä»»å‹™ç·¨ç¢¼
        converted_observations = []
        
        for obs in il_observations:
            # æå–æ ¸å¿ƒ42ç¶­æ©Ÿå™¨äººç‹€æ…‹
            robot_state = obs[:42]
            task_encoding = obs[-3:]  # ä»»å‹™ç·¨ç¢¼
            
            # æ§‹é€ 45ç¶­è§€æ¸¬ (42 + 3 = 45)
            # é€™è£¡æˆ‘å€‘ç›´æ¥ä½¿ç”¨å‰42ç¶­ + ä»»å‹™ç·¨ç¢¼ï¼Œçœç•¥è¤‡é›œçš„è½‰æ›
            research_obs = np.concatenate([robot_state, task_encoding])
            converted_observations.append(research_obs)
        
        converted_observations = np.array(converted_observations, dtype=np.float32)
        expert_actions = np.array(expert_actions, dtype=np.float32)
        
        print(f"âœ… å°ˆå®¶æ•¸æ“šè¼‰å…¥æˆåŠŸ:")
        print(f"   è§€æ¸¬: {converted_observations.shape} (89ç¶­â†’45ç¶­)")
        print(f"   å‹•ä½œ: {expert_actions.shape}")
        print(f"   Episodes: {np.sum(data['done'])}")
        
        return {
            'observations': converted_observations,
            'actions': expert_actions,
            'episode_count': int(np.sum(data['done']))
        }
    
    def get_data(self):
        """ç²å–è™•ç†å¾Œçš„å°ˆå®¶æ•¸æ“š"""
        return self.expert_data

class BCPretrainer:
    """è¡Œç‚ºå…‹éš†é è¨“ç·´å™¨ - å°ˆç‚ºæ‚¨çš„PPO-CMAç³»çµ±è¨­è¨ˆ"""
    
    def __init__(self, ppo_agent, expert_data_path, device):
        self.ppo_agent = ppo_agent
        self.device = device
        self.expert_loader = ExpertDataLoader(expert_data_path)
        self.expert_data = self.expert_loader.get_data()
        
        if self.expert_data is None:
            raise ValueError("ç„¡æ³•è¼‰å…¥å°ˆå®¶æ•¸æ“š")
        
        # BCå°ˆç”¨å„ªåŒ–å™¨ï¼ˆåªè¨“ç·´actorï¼‰
        self.bc_optimizer = torch.optim.Adam(
            self.ppo_agent.actor.parameters(),
            lr=1e-4,
            weight_decay=1e-5
        )
        
        self.loss_fn = nn.MSELoss()
    
    def pretrain(self, epochs=50, batch_size=256, print_interval=10):
        """åŸ·è¡ŒBCé è¨“ç·´"""
        if self.expert_data is None:
            print("âŒ æ²’æœ‰å°ˆå®¶æ•¸æ“šï¼Œè·³éBCé è¨“ç·´")
            return None
        
        print(f"ğŸ¯ é–‹å§‹BCé è¨“ç·´ ({epochs} epochs)")
        print(f"   æ•¸æ“šé‡: {len(self.expert_data['observations'])} æ¨£æœ¬")
        print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
        
        observations = torch.tensor(self.expert_data['observations']).to(self.device)
        actions = torch.tensor(self.expert_data['actions']).to(self.device)
        
        dataset_size = len(observations)
        best_loss = float('inf')
        
        # è¨­ç½®ç‚ºè¨“ç·´æ¨¡å¼
        self.ppo_agent.actor.train()
        
        for epoch in range(epochs):
            epoch_loss = 0
            num_batches = 0
            
            # éš¨æ©Ÿæ‰“äº‚æ•¸æ“š
            indices = torch.randperm(dataset_size)
            
            for i in range(0, dataset_size, batch_size):
                end_idx = min(i + batch_size, dataset_size)
                batch_indices = indices[i:end_idx]
                
                batch_obs = observations[batch_indices]
                batch_actions = actions[batch_indices]
                
                # å‰å‘å‚³æ’­ - ä½¿ç”¨actorç¶²çµ¡ (åªå–meanï¼Œå¿½ç•¥log_std)
                predicted_actions, _ = self.ppo_agent.actor(batch_obs)
                
                # è¨ˆç®—æå¤±
                loss = self.loss_fn(predicted_actions, batch_actions)
                
                # åå‘å‚³æ’­
                self.bc_optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.ppo_agent.actor.parameters(), 1.0)
                self.bc_optimizer.step()
                
                epoch_loss += loss.item()
                num_batches += 1
            
            avg_loss = epoch_loss / num_batches
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if avg_loss < best_loss:
                best_loss = avg_loss
                self.save_bc_model(epoch)
            
            # å®šæœŸè¼¸å‡º
            if epoch % print_interval == 0:
                print(f"   Epoch {epoch:3d}: BC Loss = {avg_loss:.6f} (Best: {best_loss:.6f})")
        
        print(f"âœ… BCé è¨“ç·´å®Œæˆ! æœ€çµ‚æå¤±: {best_loss:.6f}")
        
        # æ¢å¾©ç‚ºevaluationæ¨¡å¼
        self.ppo_agent.actor.eval()
        
        return best_loss
    
    def save_bc_model(self, epoch):
        """ä¿å­˜BCé è¨“ç·´æ¨¡å‹"""
        save_path = f"bc_pretrained_actor_epoch_{epoch}.pth"
        torch.save({
            'actor_state_dict': self.ppo_agent.actor.state_dict(),
            'epoch': epoch,
            'expert_episodes': self.expert_data['episode_count']
        }, save_path)
    
    def evaluate_bc_performance(self, num_samples=1000):
        """è©•ä¼°BCæ€§èƒ½"""
        if self.expert_data is None:
            return None
        
        self.ppo_agent.actor.eval()
        
        with torch.no_grad():
            # éš¨æ©Ÿé¸æ“‡æ¨£æœ¬
            indices = torch.randperm(len(self.expert_data['observations']))[:num_samples]
            
            test_obs = torch.tensor(self.expert_data['observations'][indices]).to(self.device)
            test_actions = torch.tensor(self.expert_data['actions'][indices]).to(self.device)
            
            # é æ¸¬å‹•ä½œ (åªå–meanï¼Œå¿½ç•¥log_std)
            predicted_actions, _ = self.ppo_agent.actor(test_obs)
            
            # è¨ˆç®—å„ç¨®èª¤å·®
            mse = nn.MSELoss()(predicted_actions, test_actions).item()
            mae = torch.mean(torch.abs(predicted_actions - test_actions)).item()
            
            # è¨ˆç®—æ¯å€‹å‹•ä½œç¶­åº¦çš„ç›¸é—œä¿‚æ•¸
            correlations = []
            for dim in range(test_actions.shape[1]):
                pred_dim = predicted_actions[:, dim].cpu().numpy()
                true_dim = test_actions[:, dim].cpu().numpy()
                corr = np.corrcoef(pred_dim, true_dim)[0, 1]
                correlations.append(corr if not np.isnan(corr) else 0)
            
            avg_correlation = np.mean(correlations)
            
        return {
            'mse': mse,
            'mae': mae,
            'avg_correlation': avg_correlation,
            'correlations_per_dim': correlations
        }

def add_bc_pretraining_to_main(expert_data_path="../data/dataset_kick.npz"):
    """
    é€™å€‹å‡½æ•¸å±•ç¤ºå¦‚ä½•å°‡BCé è¨“ç·´æ·»åŠ åˆ°æ‚¨ç¾æœ‰çš„main.py
    æ‚¨åªéœ€è¦åœ¨main.pyä¸­æ·»åŠ å¹¾è¡Œä»£ç¢¼å³å¯
    """
    code_snippet = f'''
# åœ¨æ‚¨çš„main.pyä¸­ï¼Œåœ¨å‰µå»ºPPO-CMA agentä¹‹å¾Œæ·»åŠ ä»¥ä¸‹ä»£ç¢¼:

# === BCé è¨“ç·´é›†æˆ ===
from simple_bc_integration import BCPretrainer

# æª¢æŸ¥æ˜¯å¦æœ‰å°ˆå®¶æ•¸æ“š
expert_data_path = "{expert_data_path}"
if os.path.exists(expert_data_path):
    print("ğŸ¯ ç™¼ç¾å°ˆå®¶æ•¸æ“šï¼Œé–‹å§‹BCé è¨“ç·´...")
    
    # å‰µå»ºBCé è¨“ç·´å™¨
    bc_pretrainer = BCPretrainer(ppo_cma_agent, expert_data_path, device)
    
    # åŸ·è¡Œé è¨“ç·´
    bc_loss = bc_pretrainer.pretrain(epochs=50)
    
    # è©•ä¼°BCæ€§èƒ½
    bc_performance = bc_pretrainer.evaluate_bc_performance()
    if bc_performance:
        print(f"ğŸ“Š BCæ€§èƒ½è©•ä¼°:")
        print(f"   MSE: {{bc_performance['mse']:.6f}}")
        print(f"   MAE: {{bc_performance['mae']:.6f}}")  
        print(f"   å¹³å‡ç›¸é—œä¿‚æ•¸: {{bc_performance['avg_correlation']:.4f}}")
    
    print("âœ… BCé è¨“ç·´å®Œæˆï¼Œé–‹å§‹PPO-CMAè¨“ç·´...")
else:
    print("âš ï¸ æœªæ‰¾åˆ°å°ˆå®¶æ•¸æ“šï¼Œç›´æ¥é–‹å§‹PPO-CMAè¨“ç·´...")

# ç„¶å¾Œç¹¼çºŒæ‚¨åŸæœ‰çš„è¨“ç·´å¾ªç’°...
'''
    
    print("ğŸ“‹ æ•´åˆä»£ç¢¼ç‰‡æ®µ:")
    print(code_snippet)
    
    return code_snippet

if __name__ == "__main__":
    # ç¤ºç¯„å¦‚ä½•æ•´åˆ
    add_bc_pretraining_to_main()
    
    # å¦‚æœè¦æ¸¬è©¦BCé è¨“ç·´
    expert_data_path = "../data/dataset_kick.npz"
    if os.path.exists(expert_data_path):
        print("ğŸ§ª æ¸¬è©¦BCé è¨“ç·´...")
        
        # é€™è£¡éœ€è¦æ‚¨çš„PPO agentï¼Œé€™åªæ˜¯ç¤ºç¯„
        # bc_pretrainer = BCPretrainer(your_ppo_agent, expert_data_path, device)
        # bc_pretrainer.pretrain(epochs=10)
    else:
        print(f"è«‹ç¢ºä¿å°ˆå®¶æ•¸æ“šå­˜åœ¨: {expert_data_path}")